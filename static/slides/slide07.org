#+TITLE: 極限定理
#+SUBTITLE: 第7講 - 大数の法則・中心極限定理・少数の法則
#+AUTHOR: 村田 昇
#+EMAIL: noboru.murata@gmail.com
#+DATE: 
#+STARTUP: hidestars content indent
# Time-stamp: <2024-05-24 15:28:43 mura>
:REVEAL:
#+SETUPFILE: "./reveal.js/org/mycourse.org"
# C-c C-x C-v でinlineを切り替え
# <m C-i でlatex block (math env用)
# C-c '
:END:

* COMMENT メモ
* 講義概要
:PROPERTIES:
:ID:       B0012E01-242A-48E0-B19E-AF50B72BBBCA
:END:
- 独立な確率変数の性質
- 大数の法則
- 中心極限定理
- 少数の法則

#+begin_src R :exports none :tangle no
  setwd("~/Desktop/lectures/u-tokyo/spring/course")
#+end_src
#+begin_src R :exports none
  ### 第7講 サンプルコード
#+end_src


* 基本事項の確認
:PROPERTIES:
:ID:       8704D3D8-29D5-4118-8749-1E37F3F0EEAE
:END:
#+begin_src R :exports none
  #' @exercise 基本事項の確認
#+end_src
** 確率変数
- 乱数の数学モデル : 値がランダムに決定される変数
- 任意の区間 \([a,b]\) に含まれる確率が定められている 
  - /[[color:orange][数学的には厳密性を欠くが，本講義ではこの定義]]/
- 確率変数 \(X\) が区間 \([a,b]\) \((a\leq b)\) に含まれる確率
  #+begin_quote
  \begin{equation}
    P(a\leq X\leq b)
  \end{equation}
  (特に \(a=b\) のとき \(P(X=a)\) と書く)
  #+end_quote
- 今回は有限個の値のみをとる確率変数を考える
  - /[[color:orange][無限個の値，特に連続的な値については次回以降]]/

** 平均と分散
- 確率変数 \(X\) の観測値 : \(x_1,x_2,\dotsc,x_N\)
- *平均* もしくは *期待値*
  #+begin_quote
  \begin{equation}
    \mathbb{E}[X]=\sum_{i=1}^Nx_iP(X=x_i)
  \end{equation}
  #+end_quote
- *分散* (\(=\text{標準偏差}^{2}\))
  #+begin_quote
  \begin{equation}
    \mathrm{Var}(X)
    =\mathbb{E}[(X-\mathbb{E}[X])^2]
    % =\sum_{i=1}^N(x_i-\mathbb{E}[X])^2P(X=x_i)\\
    =\mathbb{E}[X^2]-\mathbb{E}[X]^2
  \end{equation}
  #+end_quote

** 例題
:PROPERTIES:
:ID:       2CBDF9CB-1AC7-4A14-BC02-CBA85E655F7E
:END:
- [[color:green][偏ったサイコロの問題]]
  #+begin_quote
  確率変数 \(X\) は
  偶数の出る確率が奇数の2倍のサイコロの目を表すとする．
  \begin{align}
    &P(X=1)=P(X=3)=P(X=5)=1/9\\ 
    &P(X=2)=P(X=4)=P(X=6)=2/9
  \end{align}
  このとき \(X\) の平均と分散を求めよ．
  #+end_quote

#+reveal: split
- [[color:green][解答 (計算例)]]
  #+begin_quote
  \(X\) の平均は
  \begin{equation}
    \mathbb{E}[X]=\sum_{x=1}^6xP(X=x)
    ={11}/{3}=3.6666\dots
  \end{equation}
  \(X\) の分散は
  \begin{align}
    \mathbb{E}[X^2]&=\sum_{x=1}^6x^2P(X=x)={49}/{3}\\
    \mathrm{Var}(X)&={49}/{3}-{121}/{9}={26}/{9}=2.88\dots
  \end{align}
  #+end_quote

#+reveal: split
- [[color:green][解答 (Rを用いた計算例)]]
  #+begin_src R
    #' 平均と分散の計算
    p <- rep(c(1/9,2/9),3) # 確率の値 (1/9 と 2/9 を交互に3回繰り返す)
    x <- 1:6 # サイコロの目の値
    (mu <- sum(x*p)) # 平均値の計算
    (v <- sum((x-mu)^2*p)) # 分散の計算
    sqrt(v) # 標準偏差
    
    #' 正規化しないで計算する方法もある
    w <- rep(1:2,3) # 1,2 の繰り返し (確率ではない)
    weighted.mean(x,w)
    weighted.mean(x^2,w)-weighted.mean(x,w)^2
  #+end_src


* 独立性と同分布性
** 同時分布
- 観測データは確率変数の集合
- *確率変数列* \(X_1,X_2,\dotsc,X_n\) に対する考察が重要
- 定義
  #+begin_quote
  "\(X_1\) が \(x_1\) という値をとり，
  \(X_2\) が \(x_2\) という値をとり， \(\dots\) ，
  \(X_n\) が \(x_n\) という値をとる"
  という事象が起きる確率を
  *同時分布*
  という．
  \begin{equation}
    P(X_1=x_1,X_2=x_2,\dots,X_n=x_n)
  \end{equation}
  #+end_quote

** 独立性
- 無関係にサンプリングされた観測データの性質
- 定義
  #+begin_quote
  確率変数列 \(X_1,X_2,\dotsc,X_n\) が *独立* であるとは，
  任意の \(n\) 個の実数 \(x_1,x_2,\dotsc,x_n\) に対して
  \begin{multline}
    P(X_1=x_1,X_2=x_2,\dotsc,X_n=x_n)\\
    =P(X_1=x_1)\cdot P(X_2=x_2)\cdots P(X_n=x_n)
  \end{multline}
  が成り立つことをいう．
  #+end_quote
  # 直感的には
  # すべての\(i=1,\dots,n\)について,
  # \(X_i\)がとる値は\(X_1,\dotsc,X_{i-1},X_{i+1},\dotsc,X_n\)がとる値と無関係に定まるということ

** 同分布性
- 同一の法則に従って生成された観測データの性質
- 定義
  #+begin_quote
  確率変数列 \(X_1,X_2,\dotsc,X_n\) が *同分布* であるとは，
  任意の実数 \(x\) に対して
  \begin{equation}
    P(X_1=x)=P(X_2=x)=\cdots=P(X_n=x)
  \end{equation}
  が成り立つことをいう．
  #+end_quote

** 独立同分布性
- 一般に分析対象のデータには
  *独立性* と *同分布性* 
  が同時に仮定される
- 定義
  #+begin_quote
  独立かつ同分布である確率変数列を
  *独立同分布*
  もしくは
  *i.i.d.* 
  であるという．
  #+end_quote
  - i.i.d. は independent and identically distributed の略

** 無限列の独立性と同分布性
- 無限列に対しては任意の部分列について考える
- 独立性
  #+begin_quote
  \(X_1,X_2,\dotsc\) が *独立* であるとは，
  任意の正整数 \(n\) に対して \(X_1,X_2,\dotsc,X_n\) が
  独立であることをいう．
  #+end_quote
- 同分布性
  #+begin_quote
  \(X_1,X_2,\dotsc\) が *同分布* であるとは，
  任意の正整数 \(n\) に対して \(X_1,X_2,\dotsc,X_n\) が
  同分布であることをいう．
  #+end_quote
- 独立同分布性
  #+begin_quote
  \(X_1,X_2,\dotsc\) が *独立同分布*
  もしくは *i.i.d.* であるとは，
  \(X_1,X_2,\dotsc\) が独立かつ同分布であることをいう．
  #+end_quote


* 大数の法則
** 大数の法則の概要
- 要点
  #+begin_quote
  同一の法則に従って生成された集団から
  *ランダム* な観測を多数繰り返すと，
  *観測値の平均* は *真の平均値* に近づく
  #+end_quote
  # % 分析対象の一部を\alert{ランダムに}収集したデータのみを用いて(標本)平
  # % 均を計算しても, データのサンプル数が十分大きければ, その平均値は集団
  # % 全体の平均値に近い値であると考えられることは, 経験則としてよく知られ
- 例
  - [[color:green][歪みの無いコインの表が出た回数の割合]]
  - [[color:green][視聴率の調査]]
- この法則を数学的に定式化した定理が *大数の法則*

** 大数の強法則
- 定理
  #+begin_quote
  \(X_1,X_2,\dotsc\) を独立同分布な確率変数列とし，
  その平均を \(\mu\) とする．
  このとき,  \(X_1,\dotsc,X_n\) の標本平均
  \begin{equation}
    \bar{X}_n = \frac{1}{n}\sum_{i=1}^nX_i
  \end{equation}
  が \(n\to\infty\) のとき \(\mu\) に収束する確率は1である．

  これを
  "\(\bar{X}_{n}\) は
  \(n\to\infty\) のとき \(\mu\) に *概収束* する"
  という．
  #+end_quote


* 実習
:PROPERTIES:
:reveal_background: #fef4f4
:END:
** 数値実験の設計
- 方針
  #+begin_quote
  真の平均と標本平均を比較する．

  標本平均は観測データに依存するので，
  統計的な性質を見るには繰り返し実験 (Monte-Carlo法) を行う．
  #+end_quote
  - 適当な分布を設定する [[color:green][(例 : 偏りのあるサイコロ)]]
  - \(n\) 個の確率変数(乱数)の標本平均を計算する
  - 真の平均と標本平均の差を計算する
  - \(n\) を大きくしたときの差の性質を観察する
** 練習問題
:PROPERTIES:
:reveal_background: #fef4f4
:ID:       A21F23A1-42D0-4B80-A59F-AB27DF9FED39
:END:
- 大数の法則の数値実験を行いなさい．
  - 歪んだサイコロを例として，
    n回サイコロを振って標本平均(期待値)を求めたとき，
    nの値に応じて真の値と標本平均がどのくらい異なるか調べなさい．
  - nの値ごとに多数回実験を行い，
    標本平均の分布がnの値とともにどのように変化するか調べなさい．
  # - 乱数のシード値・出現確率の変更・乱数の変更などを
  #   行っても大数の法則が成立することを確認しなさい．
  # - サンプル数の増減によって精度がどの程度変わるか観察しなさい．

#+begin_src R :eval no :exports none
  #' ---------------------------------------------------------------------------
  #' @practice 大数の法則
  #' 
  set.seed(121212) # 乱数のシード値の指定
  #'
  #' 試行(離散分布の標本平均の計算)を定義する
  omega <- 1:6 # サイコロの目 (標本空間．以下では固定)
  my_mean <- function(n, p){ # 歪んだサイコロの標本平均を計算する関数
    mean(sample(omega, size = n, prob = p, replace = TRUE))}
  #' 以下の実験で明示的に変えるものを関数の引数としている
  #' * n はサイコロを振る回数
  #' * p は歪み具合
  #'(n,p ともに omega と同じように関数の外側で定義することもできる)
  #'
  #' 実験の設定
  (p <- rep(1:2, 3)) # 出現確率の比(奇数1:偶数2)を設定
  (mu <- weighted.mean(omega, p)) # 理論上の平均
  roll <- 1:6 # サイコロの目 
  probability <- p/sum(p) # 確率値に変換
  #'
  #' n毎に図を作る場合
  for(n in c(10,100,1000)){ # サンプル数を変えて実験
    xbar <- my_mean(n, p) # 1回実験を行う
    foo <- tibble(roll, probability) |>
      ggplot(aes(x = roll, y = probability)) +
      geom_bar(stat = "identity", fill = "orange", width = 0.2) +
      geom_vline(xintercept = xbar, # 標本平均 (1回の実験による推定値)
                 colour = "blue", linewidth = 1.1) +
      geom_vline(xintercept = mu,   # 真の平均
                 colour = "red", linewidth = 1.1) +
      scale_x_continuous(breaks = roll) +
      labs(title = paste("n =", n))
    print(foo) # ggplot オブジェクトはブロックの中では明示的にprintする必要がある
  }
  #'
  #' 多数のnと標本平均を1つの図で比較する場合
  nseq <- seq(10, 1000, by = 30) # 10から1000まで30おきに調べる
  xbars <- sapply(nseq, # 各値について以下の関数を計算
                  function(x) my_mean(x, p)) # '?sapply'を参照
  tibble(n = nseq, xbar = xbars) |>
    ggplot(aes(x = n, y = xbar)) +
    geom_point(colour = "blue") + # n毎の標本平均
    geom_hline(yintercept = mu,   # 真の平均
               colour = "red", linewidth = 1.1) +
    labs(y = expression(bar(X)))
  #'
  #' サンプル数の違いによる標本平均の分布を比較
  #' n毎に図を作る場合
  mc <- 1000 # Monte-Carlo実験の回数
  for(n in c(10,100,1000)){ # サンプル数を変えて実験
    xbars <- replicate(mc, my_mean(n, p)) # mc回繰り返し
    hist(xbars, breaks=20,
         col="azure", border="lightblue",
         xlim=c(1,6), ylim=c(0,200), # 複数の図を同じ領域で描画
         xlab=expression(bar(X)[n]), # help(expression), help(plotmath) 参照
         main=paste0("n=",n)) 
    abline(v=mu, col="red", lwd=2, lty="dotted")
    abline(h=0, col="grey", lwd=2, lty="solid")
  }
  #'
  #' 多数のnと標本平均を1つの図で比較する場合
  my_data <- data.frame(n=NULL,xbar=NULL) # 空のデータフレームを作成
  for(n in nseq){ # サンプル数を変えて実験
    xbars <- replicate(mc, my_mean(n,p)) # mc回繰り返し
    my_data <- rbind(my_data,data.frame(n=rep(n,mc),xbar=xbars))
  }
  boxplot(xbar ~ n, data=my_data, col="blue", 
          xlab="n", ylab=expression(bar(X))) # 標本平均(1つの観測にもとづく)
  abline(h=mu, col="red", lwd=2) # 真の平均
  #'
  #' @notes
  #' 統計的性質を見るための実験
  p <- rep(1:2, 3) # 出現確率の比(奇数1:偶数2)
  mu <- weighted.mean(omega, p) # 理論上の平均
  mc <- 1000 # Monte-Carlo実験の回数
  n <- 10 # 標本数
  xbars <- replicate(mc, my_mean(n,p)) 
  hist(xbars, breaks=20,
       col="azure", border="lightblue",
       xlim=c(1,6), ylim=c(0,200), # 描画範囲を指定
       xlab=expression(bar(X)[n]), 
       main=paste0("n=",n)) # 回数をタイトルに表示
  abline(v=mu, col="red", lwd=2, lty="dotted") # 理論値
  abline(h=0, col="grey", lwd=2, lty="solid")
  #'
  #' 乱数のシードによる違いを比較
  n <- 100 # 標本数
  for(i in c(12,34,56,78,90)){ # シード値を指定
    set.seed(i)
    xbars <- replicate(mc, my_mean(n,p)) # mc回繰り返し
    hist(xbars, breaks=20,
         col="azure", border="lightblue",
         xlim=c(1,6), ylim=c(0,200), 
         xlab=expression(bar(X)[n]), 
         main=paste0("n=",n)) 
    abline(v=mu, col="red", lwd=2, lty="dotted")
    abline(h=0, col="grey", lwd=2, lty="solid")
  }
  #'
  #' 出現確率の違いを比較
  n <- 100 # 標本数
  for(i in 1:5){ # pをランダムに設定して実験
    p <- runif(length(omega)) # 一様乱数で出現確率を設定
    mu <- weighted.mean(omega, p) # 理論上の平均
    xbars <- replicate(mc, my_mean(n,p)) # mc回繰り返し
    hist(xbars, breaks=20,
         col="azure", border="lightblue",
         xlim=c(1,6), ylim=c(0,200), 
         xlab=expression(bar(X)[n]), 
         main=paste0("n=",n)) 
    abline(v=mu, col="red", lwd=2, lty="dotted")
    abline(h=0, col="grey", lwd=2, lty="solid")
  }
  #' ---------------------------------------------------------------------------
#+end_src


* 中心極限定理
** 中心極限定理の概要
- 大数の法則の主張
  - \(n\) を大きくすると標本平均 \(\bar{X}_n\) は真の平均 \(\mu\) に近づく
  - 推定誤差 \(\bar{X}_n-\mu\) は \(n\) を大きくすると0に近づく
  - どの程度の大きさになるのか定量的な評価は与えていない
- 誤差の評価の定量化とは
  - 推定誤差がある区間 \([\alpha,\beta]\) に入る確率で定量的に評価可能
    #+begin_quote
    \begin{equation}
      P(\alpha\leq \bar{X}_n-\mu\leq \beta)
    \end{equation}
    #+end_quote
  - 上式の正確な計算は一般には困難
- サンプル数が大きい場合の定量的な評価の近似方法を述べたのが *中心極限定理*

** 中心極限定理
- 定理
  #+begin_quote
  \(X_1,X_2,\dotsc\) を独立同分布な確率変数列とし，
  その平均を \(\mu\) ，標準偏差を \(\sigma\) とする．
  このとき，すべての実数 \(a < b\) に対して
  \begin{equation}
    P\Bigl(a\leq\frac{\sqrt{n}(\bar{X}_n-\mu)}{\sigma}\leq b \Bigr)
    \to\frac{1}{\sqrt{2\pi}}\int_a^be^{-\frac{x^2}{2}}dx\quad
    (n\to\infty)
  \end{equation}
  が成り立つ．
  #+end_quote

** 中心極限定理の意味
- \(X_i\) の分布が何であっても，
  サンプル数 \(n\) が十分大きければ，
  標本平均と真の平均の差
  \(\bar{X}_n-\mu\) 
  の分布は
  *標準正規分布*
  で近似できる
  #+begin_quote
  \begin{equation}
    P\Bigl(a\frac{\sigma}{\sqrt{n}}\leq\bar{X}_n-\mu\leq
    b\frac{\sigma}{\sqrt{n}} \Bigr)
    \simeq
    \frac{1}{\sqrt{2\pi}}\int_a^be^{-\frac{x^2}{2}}dx
  \end{equation}
  #+end_quote
  - 被積分関数
    \(\phi(x)=e^{-x^2/2}/\sqrt{2\pi}\)
    を 
    *標準正規密度* 
    という
  # #+begin_quote
  #   \begin{equation}
  #     \phi(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}
  #   \end{equation}
  # #+end_quote


* 実習
:PROPERTIES:
:reveal_background: #fef4f4
:END:
** 数値実験の設計
- 方針
  #+begin_quote
  規格化した標本平均と真の平均の差
  \begin{equation}
    Z=\frac{\sqrt{n}(\bar{X}_n-\mu)}{\sigma}
  \end{equation}
  の分布と標準正規分布を比較する．
  #+end_quote
  - 中心極限定理が正しければ，
    十分小さいビン \([a,b]\) におけるヒストグラムの高さ(密度)は
    \(\phi(a)\) で近似される
  - \(Z\) を多数観測し分布(ヒストグラム)を求める
  - \(Z\) の分布と
    標準正規密度 \(\phi(x)\) を比較する
    - 密度表示は ~hist()~ で ~freq=FALSE~ を指定
    - 標準正規密度 \(\phi(x)\) は関数 ~dnorm()~ で計算可
  # \(\phi(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}\)
  # \(\sqrt{n}(\bar{X}_n-\mu)/\sigma\) のヒストグラムに
** 練習問題
:PROPERTIES:
:reveal_background: #fef4f4
:ID:       6700E410-CC78-4BC4-85BD-6EAE0A5BCE3B
:END:
- 中心極限定理の数値実験を行いなさい．
  - 歪んだサイコロを例として，
    n回サイコロを振って標本平均(期待値)を求めたとき，
    nが大きければ正規化した値は標準正規分布に従うことを確認しなさい．
  - 確率(歪み具合)が異なっても，
    上記の性質は変わらないことを確認しなさい．
  # - 乱数のシード値・出現確率の変更・乱数の変更などを行っても
  #   中心極限定理が成立することを確認しなさい．
  # - サンプル数の増減によって精度がどの程度変わるか観察しなさい．

#+begin_src R :eval no :exports none
  #' ---------------------------------------------------------------------------
  #' @practice 中心極限定理
  set.seed(232323)    # 乱数のシード値の指定
  #' 試行(離散分布の標本平均の計算)を定義する
  my_mean <- function(n,p){ # 標本平均を計算する関数
    mean(sample(omega, size=n, prob=p, replace=TRUE))}
  omega <- 1:6 # 以下サイコロの場合で実験
  mc <- 10000 # Monte-Carlo実験の繰り返し回数(大数の法則より多めに実験する)

  #' サンプル数の違いによる分布の比較
  p <- rep(1:2, 3) # 出現確率の比(奇数1:偶数2) (9で割らなくても大丈夫)
  (mu <- weighted.mean(omega, p)) # 理論上の平均
  (sigma <- sqrt( # 理論上の標準偏差(分散の平方根)
     weighted.mean(omega^2,p)-mu^2)) 
  for(n in c(2,10,100,1000)){ # サンプル数を変えて実験
    xbars <- replicate(mc, my_mean(n,p)) # mc回繰り返し
    hist(sqrt(n)*(xbars - mu)/sigma, breaks=30,
         freq=FALSE, # 密度で表示
         xlim=c(-3, 3), ylim=c(0,0.55),  
         col="orange", border="orchid",
         xlab=expression(sqrt(n)*(bar(X)[n]-mu)/sigma),
         main=paste0("n=",n))
    curve(dnorm, add=TRUE, col="red", lwd=2) # 理論曲線
  }

  #' 出現確率の違いによる分布の比較
  n <- 100 # 標本数 (いろいろ変えて実験せよ．nが小さいとpの影響が大きい)
  for(i in 1:5){ # pをランダムに設定して実験
    p <- runif(length(omega)) # 一様乱数で出現確率を設定
    mu <- weighted.mean(omega, p) # 理論上の平均
    sigma <- sqrt( # 理論上の標準偏差(分散の平方根)
      weighted.mean(omega^2,p)-mu^2)
    xbars <- replicate(mc, my_mean(n,p)) 
    hist(sqrt(n)*(xbars - mu)/sigma, breaks=30,
         freq=FALSE, 
         xlim=c(-3, 3), ylim=c(0,0.55),  
         col="orange", border="orchid",
         xlab=expression(sqrt(n)*(bar(X)[n]-mu)/sigma),
         main=paste0("p=",toString(round(p,2))))
    curve(dnorm, add=TRUE, col="red", lwd=2) 
  }
  #' ---------------------------------------------------------------------------
#+end_src


* 少数の法則
** 少数の法則の概要
- 滅多に起きない事が起こる回数に関する法則
- [[color:green][例 : 不良品発生率の低い工場での日々の不良品の個数の分布]]
  #+begin_quote
  ある製品の不良品率 \(p\) はとても小さいとする.

  一日に \(n\) 個(非常に多数とする)生産するとき，
  不良品は平均的には \(\lambda=np\) 個発生するが，
  日によって不良品の個数 \(S_n\) には多少のばらつきが生じる．

  個数 \(S_n\) は確率変数であり，
  強度 \(\lambda\) の *Poisson 分布* で近似できる．
  #+end_quote
- この状況を正確に述べたのが *少数の法則*

** 少数の法則
- 定理の問題設定
  #+begin_quote
  \(X_1,X_2,\dotsc,X_n\) を独立な確率変数列とし，
  各 \(i=1,2,\dotsc,n\) について 
  \(X_i\) は確率 \(p_{n,i}\) で 1 を，
  確率 \(1-p_{n,i}\) で 0 をとるとする
  \begin{align}
    &P(X_i=1)=p_{n,i},\\
    &P(X_i=0)=1-p_{n,i}\quad
      (i=1,2,\dots,n).
  \end{align}
  #+end_quote

#+reveal: split
- 定理
  #+begin_quote
  このとき
  ある正の実数 \(\lambda\) が存在して, \(n\to\infty\) のとき
  \begin{equation}
    \max_{i=1,2,\dots,n}p_{n,i}\to0,\quad
    \sum_{i=1}^np_{n,i}\to\lambda
  \end{equation}
  ならば，任意の整数 \(k\geq0\) に対して以下が成り立つ:
  \begin{equation}
    P\Bigl(\sum_{i=1}^nX_i=k\Bigr)
    \to e^{-\lambda}\frac{\lambda^k}{k!}
    \quad(n\to\infty).
  \end{equation}
  #+end_quote
  - 定理の \(\sum_{i=1}^nX_i\) が不良品の例の \(S_n\) に対応

** Poisson 分布
- 定義
  #+begin_quote
  確率変数 \(X\) の取りうる値が0以上の整数全体で，
  値が整数 \(k\geq0\) となる確率が
  \begin{equation}
    P(X=k)=e^{-\lambda}\frac{\lambda^k}{k!}
  \end{equation}
  で与えられるものを強度
  \(\lambda\) の *Poisson 型確率変数* 
  その確率法則を強度 \(\lambda\) の *Poisson 分布* と呼ぶ．
  #+end_quote


* 実習
:PROPERTIES:
:reveal_background: #fef4f4
:END:
** 数値実験の設計
- 方針
  #+begin_quote
  小さな確率で \(X=1\) となる確率変数を多数観測し，
  その合計値の分布を調べ，
  Poisson 分布と比較する．
  #+end_quote
  - 確率 \(P(X=1)=p\) を小さな値に設定する
  - \(n\) 個(非常に多数)の確率変数の合計 \(S_n\) を計算する
  - \(S_n\) を多数観測し分布を求める
  - \(S_n\) の分布を
    強度 \(\lambda=pn\) の Poisson 分布と比較する
    - 確率 \(p\) サイズ \(n\) の二項乱数 ~rbinom()~ が利用可能
    - Poissson 分布の確率値は関数 ~dpois()~ で計算可能

** 練習問題
:PROPERTIES:
:reveal_background: #fef4f4
:ID:       F13E9177-30B8-4A34-A730-6345B6CAF5B6
:END:
- 少数の法則の数値実験を行いなさい．
  - 1日の総生産量 (\(n\)) が 5000，
    不良品の発生確率 (\(p\)) が 0.002 である工場を例として，
    2年間の操業(週5日x50週間)
    において観測される不良品数の分布を確認しなさい．
  - 母数 \(n,p\) の違いによって結果がどのように変わるか観察しなさい．

#+begin_src R :eval no :exports none
  #' ---------------------------------------------------------------------------
  #' @practice 少数の法則
  set.seed(343434) # 乱数のシード値の指定

  #' 基本の実験
  n <- 5000    # 1日の総生産量
  p <- 0.002   # 不良品の発生確率
  N <- 5*50*2  # 観測日数(週5日x50週間x2年操業に対応)
  x <- rbinom(N,n,p) # 不良品数
  #' x <- replicate(N, rbinom(1,n,p)) # これでも同じ
  (my_data <- table(x)) # 不良品数の度数分布表を作成
  #' それぞれの不良品数が生じた日数の割合のグラフを作成
  if(Sys.info()["sysname"]=="Darwin"){par(family="HiraginoSans-W4")} # 日本語表示
  plot(my_data/N, type="h", col="royalblue", lwd=6, 
       xlab="不良品数", ylab="発生割合")
  lines(min(x):max(x)+0.4, dpois(min(x):max(x),n*p),
        type="h", col="red", lwd=6) # 理論上の割合
  legend("topright", inset=1/20, # 右上に配置
         legend=c("観測値", "理論値"), 
         col=c("royalblue", "red"), lwd=4) # 凡例

  #' nの違いを比較
  p <- 0.002
  for(n in c(500,1000,5000,10000)){
    x <- rbinom(N,n,p) # 不良品数
    my_data <- table(x)/N # 集計
    if(Sys.info()["sysname"]=="Darwin"){par(family="HiraginoSans-W4")} # 日本語表示
    plot(my_data, type="h", col="royalblue", lwd=6, 
         xlab="不良品数", ylab="発生割合",
         main=paste("n =",n,"p =",p))
    lines(min(x):max(x)+0.4, dpois(min(x):max(x),n*p),
          type="h", col="red", lwd=6) 
  }

  #' pの違いを比較
  n <- 5000
  for(p in c(0.001,0.002,0.005,0.01)){
    x <- rbinom(N,n,p) # 不良品数
    my_data <- table(x)/N # 集計
    if(Sys.info()["sysname"]=="Darwin"){par(family="HiraginoSans-W4")} # 日本語表示
    plot(my_data, type="h", col="royalblue", lwd=6, 
         xlab="不良品数", ylab="発生割合",
         main=paste("n =",n,"p =",p))
    lines(min(x):max(x)+0.4, dpois(min(x):max(x),n*p),
          type="h", col="red", lwd=6) 
  }
  #' n が大きくなるに従い，正規分布の形に近付いていくことが観測できる
  #' 中心極限定理がここでも成り立っていることがわかる
  #' ---------------------------------------------------------------------------
#+end_src


* 補遺
** 重複対数の法則
- 定理
  #+begin_quote
  \(X_1,X_2,\dotsc\) を独立同分布な確率変数列とし，
  その平均を \(\mu\) ，標準偏差を \(\sigma\) とする．
  このとき
  \begin{align}
    &\limsup_{n\to\infty}
      \frac{\sqrt{n}(\bar{X}_{n}-\mu)}
      {\sqrt{2\sigma^2\log\log n}}
      =1\quad\text{a.s.},\\
    &\liminf_{n\to\infty}
      \frac{\sqrt{n}(\bar{X}_{n}-\mu)}
      {\sqrt{2\sigma^2\log\log n}}
      =-1\quad\text{a.s.}
  \end{align}
  が成り立つ．
  #+end_quote
  - 大数の法則と中心極限定理の中間的な評価と考えることができる

** Hartman-Wintnerの定理
- 定理
  #+begin_quote
  前定理の条件のもと，列
  \begin{equation}
    \left\{
      \frac{\sqrt{n}(\bar{X}_{n}-\mu)}
      {\sqrt{2\sigma^2\log\log n}}
    \right\}_{n=3}^{\infty}
  \end{equation}
  のある部分列の収束先となるような実数全体の集合を \(C\) とすると，
  \(C\) が閉区間 \([-1,1]\) に一致する確率は1である. 
  #+end_quote


* 次回の予定
- 一般の確率変数
- 離散分布
  - 離散一様分布・二項分布
  - Poisson 分布・幾何分布
- 連続分布
  - 一様分布・正規分布
  - ガンマ分布・\(t\)-分布・\(F\)-分布

* Footnotes
* COMMENT ローカル変数
# Local Variables:
# org-latex-listings: minted
# End:
   
